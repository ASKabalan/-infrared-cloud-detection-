{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# pylint: disable=E1102\n",
    "\n",
    "import jax\n",
    "from dataloader import DataLoader, chosen_datasets\n",
    "from flax.training.early_stopping import EarlyStopping\n",
    "from model import create_train_state, eval_function, load_model, pred_function, save_model, update_model\n",
    "from plots import loss_and_accuracy, matrix_confusion, roc\n",
    "from tqdm import tqdm\n",
    "from utils import check_slurm_mode, get_folders, get_statistics, get_user_data_general, get_user_data_network, number_clear_cloud\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# USER PARAMETERS\n",
    "BATCH_SIZE, NB_EPOCHS, EARLY_STOP, TYPE_OPTIMIZER, MOMENTUM = get_user_data_network()\n",
    "NAME_DB, PATH_FOLDERS, DIRECTORIES, PERCENTAGE, NORMA = get_user_data_general()\n",
    "FOLDERS = get_folders(PATH_FOLDERS, NAME_DB, DIRECTORIES)\n",
    "FOLDER_DATABASE, FOLDER_PLOTS, FOLDER_MODELS = FOLDERS[0], FOLDERS[1], FOLDERS[2]\n",
    "case = f\"ResNet_batch{str(BATCH_SIZE)}_epoch{str(NB_EPOCHS)}\"\n",
    "\n",
    "# CREATE DATASETS\n",
    "path_image_files = sorted(FOLDER_DATABASE.glob(\"*.fits\"))\n",
    "path_labels_files = sorted(FOLDER_DATABASE.glob(\"*.npy\"))\n",
    "train_images_files, train_labels_files, test_images_files, test_labels_files = chosen_datasets(PERCENTAGE, path_image_files, path_labels_files)\n",
    "MEAN_GLOBAL, STD_GLOBAL, MIN_GLOBAL, MAX_GLOBAL = get_statistics(train_images_files)\n",
    "\n",
    "# CONFIG\n",
    "NB_BATCH_TRAIN = len(train_images_files) // BATCH_SIZE + 1\n",
    "NB_BATCH_TEST = len(test_images_files) // BATCH_SIZE + 1\n",
    "print(f\"TRAIN_IMGS {len(train_images_files)} & NB CLEAR/CLOUD IMAGES\", number_clear_cloud(train_labels_files))\n",
    "print(f\"TEST_IMGS {len(test_images_files)} & NB CLEAR/CLOUD IMAGES\", number_clear_cloud(test_labels_files))\n",
    "print(f\"PERCENTAGE train/test : {PERCENTAGE} & NB of BATCH_TRAIN {NB_BATCH_TRAIN} NB of BATCH_TEST {NB_BATCH_TEST}\")\n",
    "\n",
    "# SPECIFICS NN\n",
    "early_stopping = EarlyStopping(min_delta=1e-9, patience=EARLY_STOP)\n",
    "state, dropout_key, schedule = create_train_state(TYPE_OPTIMIZER, NB_EPOCHS, NB_BATCH_TRAIN, MOMENTUM)\n",
    "dataloader_train = DataLoader(train_images_files, train_labels_files, BATCH_SIZE, MEAN_GLOBAL, STD_GLOBAL, MIN_GLOBAL, MAX_GLOBAL, normalisation=NORMA)\n",
    "dataloader_test = DataLoader(test_images_files, test_labels_files, BATCH_SIZE, MEAN_GLOBAL, STD_GLOBAL, MIN_GLOBAL, MAX_GLOBAL, shuffle=False, normalisation=NORMA)\n",
    "\n",
    "# TRAINING\n",
    "TQDM_DISABLE = check_slurm_mode()\n",
    "list_avg_losses, list_avg_accuracies, list_avg_test_losses, list_avg_test_accuracies = [], [], [], []\n",
    "\n",
    "for epoch in range(NB_EPOCHS):\n",
    "    list_losses, list_accuracies, list_test_losses, list_test_accuracies = [], [], [], []\n",
    "\n",
    "    # LOOP OVER ALL TRAIN BATCHES\n",
    "    for batch_images_train, batch_labels_train in tqdm(dataloader_train.generate_batches(), total=NB_BATCH_TRAIN, desc=f\"epoch {epoch+1}\", disable=TQDM_DISABLE):\n",
    "        state, loss, accuracy = update_model(state, batch_images_train, batch_labels_train, dropout_key)\n",
    "        list_losses.append(loss)\n",
    "        list_accuracies.append(accuracy)\n",
    "\n",
    "    # LOOP OVER ALL TEST BATCHES\n",
    "    for batch_images_test, batch_labels_test in tqdm(dataloader_test.generate_batches(), total=NB_BATCH_TEST, desc=\"test batches\", disable=TQDM_DISABLE):\n",
    "        test_loss, test_accuracies = eval_function(state, batch_images_test, batch_labels_test)\n",
    "        list_test_losses.append(test_loss)\n",
    "        list_test_accuracies.append(test_accuracies)\n",
    "\n",
    "    # SAVE RESULTS FOR PLOTS\n",
    "    avg_losses = jax.numpy.mean(jax.numpy.stack(list_losses))\n",
    "    list_avg_losses.append(avg_losses)\n",
    "    avg_accuracies = jax.numpy.mean(jax.numpy.stack(list_accuracies))\n",
    "    list_avg_accuracies.append(avg_accuracies)\n",
    "    avg_test_losses = jax.numpy.mean(jax.numpy.stack(list_test_losses))\n",
    "    list_avg_test_losses.append(avg_test_losses)\n",
    "    avg_test_accuracies = jax.numpy.mean(jax.numpy.stack(list_test_accuracies))\n",
    "    list_avg_test_accuracies.append(avg_test_accuracies)\n",
    "    lr = schedule(state.step).item()\n",
    "    print(f\"loss train {avg_losses:.1e} / loss val {avg_test_losses:.1e} / acc train {avg_accuracies} / acc val {avg_test_accuracies}  / lr {lr:.1e}\")\n",
    "\n",
    "    # EARLY-STOPPING\n",
    "    has_improved, early_stopping = early_stopping.update(metric=avg_losses)\n",
    "    if has_improved:\n",
    "        save_model(state, FOLDER_MODELS / case)\n",
    "    if early_stopping.should_stop:\n",
    "        print(f\"Met early stopping criteria, breaking at epoch {epoch}\")\n",
    "        break\n",
    "\n",
    "# PLOTS\n",
    "list_preds, list_truths = [], []\n",
    "best_state_model = load_model(FOLDER_MODELS / case)\n",
    "for batch_images_test, batch_labels_test in tqdm(dataloader_test.generate_batches(), total=NB_BATCH_TEST, desc=\"PLOTS COMPUTATIONS\"):\n",
    "    list_preds.append(pred_function(best_state_model, batch_images_test))\n",
    "    list_truths.append(batch_labels_test)\n",
    "\n",
    "concatenated_preds, concatenated_truth = jax.numpy.concatenate(list_preds, axis=0), jax.numpy.concatenate(list_truths, axis=0)\n",
    "matrix_confusion(concatenated_truth, concatenated_preds, FOLDER_PLOTS, case, title=\"RESNET\")\n",
    "roc(concatenated_preds, concatenated_truth, FOLDER_PLOTS, case=f\"{case}_preds\")\n",
    "loss_and_accuracy(list_avg_losses, list_avg_test_losses, list_avg_accuracies, list_avg_test_accuracies, FOLDER_PLOTS, case)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
